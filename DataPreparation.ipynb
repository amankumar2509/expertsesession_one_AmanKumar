{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc60b09",
   "metadata": {},
   "source": [
    "# Database Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d47512",
   "metadata": {},
   "source": [
    "## In this notebook we will prepare our data for our search function to use. \n",
    "## Currently we have data stored in two different csv files.\n",
    "* cars.csv\n",
    "* newcars.csv\n",
    "\n",
    "\n",
    "It can be computationally expensive to produce analysis results from multiple data-sources for incomming stream of requests. So we will prepare our data and save it in an easily searchable structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbd479a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed modules...\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8b2e0",
   "metadata": {},
   "source": [
    "# Define Paths to data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4b0044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TESTS   = f\"{getcwd()}/dataStore/test.csv\"\n",
    "PATH_TRAINS  = f\"{getcwd()}/dataStore/train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7b372",
   "metadata": {},
   "source": [
    "# Data Engineering\n",
    "* Get data in dataframes.\n",
    "* Convert data to a single dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "149761e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['id', 'car_name', 'yr_mfr', 'fuel_type', 'kms_run', 'sale_price', 'city', 'times_viewed', 'body_type', 'transmission', 'variant', 'assured_buy', 'registered_city', 'registered_state', 'is_hot', 'rto', 'source', 'make', 'model', 'car_availability', 'total_owners', 'broker_quote', 'original_price', 'car_rating', 'ad_created_on', 'fitness_certificate', 'emi_starts_from', 'booking_down_pymnt', 'reserved', 'warranty_avail']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from test.csv\n",
    "\"\"\"\n",
    "df_tests            = pd.read_csv(PATH_TESTS)\n",
    "tests_table_columns = df_tests.columns.tolist()\n",
    "print(f\"COLUMNS : {tests_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b934a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['id', 'car_name', 'yr_mfr', 'fuel_type', 'kms_run', 'sale_price', 'city', 'times_viewed', 'body_type', 'transmission', 'variant', 'assured_buy', 'registered_city', 'registered_state', 'is_hot', 'rto', 'source', 'make', 'model', 'car_availability', 'total_owners', 'broker_quote', 'original_price', 'car_rating', 'ad_created_on', 'fitness_certificate', 'emi_starts_from', 'booking_down_pymnt', 'reserved', 'warranty_avail']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from train.csv\n",
    "\"\"\"\n",
    "df_trains            = pd.read_csv(PATH_TRAINS)\n",
    "trains_table_columns = df_trains.columns.tolist()\n",
    "print(f\"COLUMNS : {trains_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "394dc2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is True  that the column 'id' has unique values for all entries in tests dataframe.\n",
      "It is True  that the column 'id' has unique values for all entries in trains dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(f\"It is {pd.Series(df_tests['id']).is_unique}  that the column 'id' has unique values for all entries in tests dataframe.\")\n",
    "print(f\"It is {pd.Series(df_trains['id']).is_unique}  that the column 'id' has unique values for all entries in trains dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2754a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort test dataframe on the basis of id as id is unique for all entries...\n",
    "df_tests_sorted = df_tests.sort_values(by=['id'])\n",
    "\n",
    "# Sort links dataframe on the basis of movieId as movieId is unique for all entries...\n",
    "df_trains_sorted  = df_trains.sort_values(by=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bee04a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tests dataframe...\n",
    "testIds    = df_tests_sorted[\"id\"].tolist()\n",
    "carnamess = df_tests_sorted[\"car_name\"].tolist()\n",
    "fueltypes = [fueltype.split(\"|\") for fueltype in df_tests[\"fuel_type\"].tolist()]\n",
    "\n",
    "# from trains dataframe...\n",
    "car_rating  = df_trains_sorted[\"car_rating\"].tolist()\n",
    "original_price = df_trains_sorted[\"original_price\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac371ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict             = {}\n",
    "global_secondaryIndex = {}\n",
    "for idx, id in enumerate(testIds):\n",
    "    testDict[id] = {\n",
    "        \"fueltype\" : fueltypes[idx],\n",
    "        \"trains\" : {\n",
    "            \"car_rating\" : car_rating[idx], \n",
    "            \"original_price\" : original_price[idx]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    global_secondaryIndex[carnamess[idx]] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "852b0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete veriables which are no longer in use while holding large amount of data.\n",
    "del testIds\n",
    "del carnamess\n",
    "del fueltypes\n",
    "del car_rating\n",
    "del original_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ff1b1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Writing car Data into the disk...\n",
      "[INFO] Writing Global Secondary Index Data into the disk...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"[INFO] Writing car Data into the disk...\")\n",
    "with open('dataStore/dataFinal.json', 'w') as fp:\n",
    "    json.dump(testDict, fp, sort_keys=True, indent=4)\n",
    "print(\"[INFO] Writing Global Secondary Index Data into the disk...\")\n",
    "with open('dataStore/dataFinal_GIS.json', 'w') as fp:\n",
    "    json.dump(global_secondaryIndex, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519bb55",
   "metadata": {},
   "source": [
    "### At this point, our database is ready and it can handle high inflow of requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc0a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
